{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZakiyQirosM/GLAURA-model/blob/main/Glaura_DenseNet169_non_augmentasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIw1bt4_haZA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import torchvision\n",
        "import os\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7ajhMOnhgZf"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d deathtrooper/glaucoma-dataset-eyepacs-airogs-light-v2 -p /content/sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkWacGevh0_N"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"/content/sample_data/glaucoma-dataset-eyepacs-airogs-light-v2.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVBXrEsth5S4"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/eyepac-light-v2-512-jpg'\n",
        "\n",
        "for main_folder in ['train', 'test', 'validation']:\n",
        "    print(main_folder.upper())\n",
        "    for sub_folder in ['RG', 'NRG']:\n",
        "        folder_path = os.path.join(dataset_path, main_folder, sub_folder)\n",
        "        num_files = len(os.listdir(folder_path))\n",
        "        print(f\"{sub_folder}: {num_files}\")\n",
        "    print(\"=================================\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOF6dkcbEJI7"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5UThj0ch-Dk"
      },
      "source": [
        "# **DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_SuFzc4DiVp"
      },
      "outputs": [],
      "source": [
        "stats = ((0.3569, 0.2273, 0.1467), (0.2023, 0.1994, 0.210))\n",
        "data_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(*stats, inplace=True)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YY0_M-aD6Dx"
      },
      "outputs": [],
      "source": [
        "EPOCH = 10\n",
        "BATCH_SIZE = 15\n",
        "LR = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h2aCi60DtdX"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(os.path.join(dataset_path, 'train'), transform=data_transform)\n",
        "test_dataset = datasets.ImageFolder(os.path.join(dataset_path, 'test'), transform=data_transform)\n",
        "validation_dataset = datasets.ImageFolder(os.path.join(dataset_path, 'validation'), transform=data_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OtF7x1KEdYD"
      },
      "outputs": [],
      "source": [
        "def fit(\n",
        "    model : torchvision.models,\n",
        "    epoch : int,\n",
        "    train_loader : torch.utils.data.DataLoader,\n",
        "    val_loader : torch.utils.data.DataLoader,\n",
        "    *args, **kwargs\n",
        ") -> dict:\n",
        "\n",
        "    TRAIN_LOSS, TRAIN_ACC = [], []\n",
        "    train_batches = len(train_loader)\n",
        "\n",
        "    VAL_LOSS, VAL_ACC = [], []\n",
        "    val_batches = len(val_loader)\n",
        "\n",
        "    # loop for every epoch (training + evaluation)\n",
        "    start_ts = time.time()\n",
        "    for e in range(epoch):\n",
        "        train_losses = 0\n",
        "        train_accuracies = 0\n",
        "\n",
        "        # progress bar\n",
        "        progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=train_batches)\n",
        "\n",
        "        # ----------------- TRAINING  --------------------\n",
        "        # set model to training\n",
        "        model.train()\n",
        "\n",
        "        for i, data in progress:\n",
        "            X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # training step for single batch\n",
        "            model.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(X)\n",
        "            loss = loss_function(outputs, y)\n",
        "\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses += loss.item()\n",
        "\n",
        "            ps = torch.exp(outputs)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == y.view(*top_class.shape)\n",
        "            train_accuracies += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            # updating progress bar\n",
        "            progress.set_description(\"Loss: {:.4f}\".format(train_losses/(i+1)))\n",
        "\n",
        "        TRAIN_ACC.append(train_accuracies/train_batches)\n",
        "        TRAIN_LOSS.append(train_losses/train_batches)\n",
        "\n",
        "        # releasing unceseccary memory in GPU\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # ----------------- VALIDATION  -----------------\n",
        "        val_losses = 0\n",
        "        val_accuracies = 0\n",
        "\n",
        "        # set model to evaluating (testing)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                X, y = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(X) # this gives the prediction from the network\n",
        "                val_losses += loss_function(outputs, y).item()\n",
        "\n",
        "                ps = torch.exp(outputs)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == y.view(*top_class.shape)\n",
        "                val_accuracies += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        print(\"Epoch {}/{} >> Training loss: {:.3f}, Validation loss: {:.3f}, Validation accuracy: {:.3f}\".format(\n",
        "            e+1, epoch, train_losses/train_batches, val_losses/val_batches, val_accuracies/val_batches*100)\n",
        "        )\n",
        "\n",
        "        VAL_ACC.append(val_accuracies/val_batches)\n",
        "        VAL_LOSS.append(val_losses/val_batches)\n",
        "\n",
        "    tr_time = time.time()-start_ts\n",
        "    print(\"Training time: {:.3f}s\".format(tr_time))\n",
        "\n",
        "    return {\n",
        "        \"model\" : model.name,\n",
        "        \"train_acc\" : TRAIN_ACC,\n",
        "        \"train_loss\" : TRAIN_LOSS,\n",
        "        \"val_acc\" : VAL_ACC,\n",
        "        \"val_loss\" : VAL_LOSS,\n",
        "        \"exc_time\" : tr_time\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe6AJMpNFp8V"
      },
      "outputs": [],
      "source": [
        "def plot_performance(dict_ : dict, *args, **kwargs) -> None:\n",
        "    my_figure = plt.figure(figsize=(12, 4))\n",
        "    # NOTE: figsize=(width/horizontally, height/vertically)\n",
        "\n",
        "    m = my_figure.add_subplot(121)\n",
        "    plt.plot(dict_[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(dict_[\"val_loss\"], label=\"Valid. Loss\")\n",
        "    plt.title(\"LOSS\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "\n",
        "    n = my_figure.add_subplot(122)\n",
        "    plt.plot(dict_[\"train_acc\"], label=\"Train Accuracy\")\n",
        "    plt.plot(dict_[\"val_acc\"], label=\"Valid. Accuracy\")\n",
        "    plt.title(\"ACCURACY\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaNaE7QtFrA4"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfpPKZlxFvQH"
      },
      "outputs": [],
      "source": [
        "EPOCH = 10\n",
        "BATCH_SIZE = 10\n",
        "LEARNING_RATE = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6rkt79QF2Uu"
      },
      "outputs": [],
      "source": [
        "model = models.densenet169(pretrained=True)\n",
        "model.name = \"densenet169\"\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-gCTmllHIRL"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAcn2ZfuHSTx"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "result = fit(model, EPOCH, train_loader, valid_loader, loss_function, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4xEyhYYiwfa"
      },
      "outputs": [],
      "source": [
        "plot_performance(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOwhe2GHjkBz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'Glaura-DenseNet169.pth')"
      ],
      "metadata": {
        "id": "EbTXCog3Fctb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "models = {\n",
        "    \"DenseNet121\": tf.keras.applications.DenseNet121,\n",
        "    \"DenseNet169\": tf.keras.applications.DenseNet169,\n",
        "    \"ResNet50\": tf.keras.applications.ResNet50\n",
        "}\n",
        "\n",
        "for model_name, model_func in models.items():\n",
        "    model = model_func(weights=None)\n",
        "    total_params = model.count_params()\n",
        "    print(f\"{model_name}: {total_params:,} parameters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIH8V79rpit0",
        "outputId": "c34aa53c-47de-43f7-9b30-15d292354fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet121: 8,062,504 parameters\n",
            "DenseNet169: 14,307,880 parameters\n",
            "ResNet50: 25,636,712 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_C1Q3q9Tq8Ot"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}